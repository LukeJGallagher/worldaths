name: Weekly Data Sync

on:
  schedule:
    # Run every Sunday at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      full_refresh:
        description: 'Run full data refresh'
        required: false
        default: 'false'
        type: boolean

jobs:
  sync-data:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Validate existing data
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          echo "Validating current Azure data..."
          python backup_manager.py validate || echo "No existing data to validate"

      - name: Create backup before sync
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          echo "Creating backup..."
          python -c "
          from backup_manager import create_backup, get_blob_service, CONTAINER_NAME
          blob_service = get_blob_service()
          container = blob_service.get_container_client(CONTAINER_NAME)
          for filename in ['master.parquet', 'ksa_profiles.parquet', 'benchmarks.parquet']:
              try:
                  from backup_manager import create_backup
                  # Create timestamped backup
                  from datetime import datetime
                  timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                  source = container.get_blob_client(f'athletics/{filename}')
                  if source.exists():
                      backup = container.get_blob_client(f'athletics/backups/{filename}_{timestamp}')
                      backup.start_copy_from_url(source.url)
                      print(f'Backed up: {filename}')
              except Exception as e:
                  print(f'Backup skipped for {filename}: {e}')
          "

      - name: Run data conversion and upload
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          echo "Converting and uploading data..."
          python convert_to_parquet.py

      - name: Verify uploaded data
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          echo "Verifying Azure data..."
          python backup_manager.py list

      - name: Cleanup old backups
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          echo "Cleaning up old backups (keeping 7 daily, 4 weekly)..."
          python -c "
          from backup_manager import get_blob_service, CONTAINER_NAME, cleanup_old_backups
          blob_service = get_blob_service()
          container = blob_service.get_container_client(CONTAINER_NAME)
          cleanup_old_backups(container)
          "

      - name: Generate NotebookLM briefings
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          echo "Generating briefings for NotebookLM..."
          python generate_briefings.py
          echo "Briefings generated in briefings/ folder"
          ls -la briefings/
          ls -la briefings/athletes/ 2>/dev/null || echo "No athlete profiles directory"
          echo ""
          echo "NOTE: NotebookLM upload requires interactive Google OAuth (cannot run in CI)."
          echo "After this workflow completes, run locally:"
          echo "  python generate_briefings.py --upload              # Upload briefings only"
          echo "  python generate_briefings.py --full-pipeline       # Upload + generate audio"

      - name: Upload briefings to Azure Static Website
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          echo "Uploading briefings to Azure $web container..."
          python -c "
          from azure.storage.blob import BlobServiceClient, ContentSettings
          import os
          from datetime import datetime

          conn_str = os.environ['AZURE_STORAGE_CONNECTION_STRING']
          blob_service = BlobServiceClient.from_connection_string(conn_str)

          # Use \$web container for static website hosting
          container = blob_service.get_container_client('\$web')

          # Create index.html
          index_html = '''<!DOCTYPE html>
          <html>
          <head>
            <title>KSA Athletics Intelligence</title>
            <meta charset=\"UTF-8\">
            <style>
              body { font-family: Inter, sans-serif; max-width: 900px; margin: 0 auto; padding: 20px; background: #f8f9fa; }
              h1 { color: #007167; }
              .card { background: white; padding: 20px; margin: 15px 0; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-left: 4px solid #007167; }
              a { color: #007167; text-decoration: none; font-weight: 500; }
              a:hover { text-decoration: underline; }
              .updated { color: #666; font-size: 0.9em; margin-bottom: 20px; }
              pre { background: #f5f5f5; padding: 15px; overflow-x: auto; border-radius: 4px; }
            </style>
          </head>
          <body>
            <h1>KSA Athletics Intelligence</h1>
            <p class=\"updated\">Last updated: ''' + datetime.now().strftime('%d %B %Y %H:%M UTC') + '''</p>
            <div class=\"card\"><a href=\"athletics/00_combined_briefing.md\">Combined Briefing (All Data)</a><p>Complete overview of all KSA athletes, rankings, and analysis</p></div>
            <div class=\"card\"><a href=\"athletics/01_athlete_overview.md\">Athlete Overview</a><p>Top 20 athletes by world ranking, grouped by event</p></div>
            <div class=\"card\"><a href=\"athletics/02_gap_analysis.md\">Gap Analysis</a><p>Gaps to medal standards at major championships</p></div>
            <div class=\"card\"><a href=\"athletics/03_competitor_intelligence.md\">Competitor Intelligence</a><p>Key rivals in priority events</p></div>
            <div class=\"card\"><a href=\"athletics/04_asian_games_focus.md\">Asian Games 2026 Focus</a><p>Project East medal targets and strategy</p></div>
          </body>
          </html>'''

          # Upload index.html
          blob = container.get_blob_client('index.html')
          blob.upload_blob(index_html, overwrite=True, content_settings=ContentSettings(content_type='text/html'))
          print('Uploaded: index.html')

          # Upload briefings
          for f in os.listdir('briefings'):
              if f.endswith('.md'):
                  blob = container.get_blob_client(f'athletics/{f}')
                  with open(f'briefings/{f}', 'rb') as data:
                      blob.upload_blob(data, overwrite=True, content_settings=ContentSettings(content_type='text/markdown'))
                  print(f'Uploaded: athletics/{f}')

          # Upload individual athlete profiles
          athletes_dir = 'briefings/athletes'
          if os.path.exists(athletes_dir):
              for f in os.listdir(athletes_dir):
                  if f.endswith('.md'):
                      blob = container.get_blob_client(f'athletics/athletes/{f}')
                      with open(f'{athletes_dir}/{f}', 'rb') as data:
                          blob.upload_blob(data, overwrite=True, content_settings=ContentSettings(content_type='text/markdown'))
                      print(f'Uploaded: athletics/athletes/{f}')

          print()
          print('Static website URL: Check Azure Portal for your storage account primary endpoint')
          print('Format: https://<storage-account>.z6.web.core.windows.net/')
          "

      - name: Report status
        if: always()
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          echo "=== SYNC COMPLETE ==="
          python -c "
          from backup_manager import get_blob_service, CONTAINER_NAME
          blob_service = get_blob_service()
          container = blob_service.get_container_client(CONTAINER_NAME)
          total = 0
          print('Current files:')
          for blob in container.list_blobs(name_starts_with='athletics/'):
              if not '/backups/' in blob.name and not '/baseline/' in blob.name:
                  size_mb = blob.size / (1024*1024)
                  total += blob.size
                  print(f'  {blob.name}: {size_mb:.2f} MB')
          print(f'Total: {total/(1024*1024):.2f} MB')
          "
